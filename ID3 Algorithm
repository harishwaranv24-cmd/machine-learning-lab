import pandas as pd
import numpy as np
import math

# Load Dataset
data = pd.read_csv("two.csv")

print("Dataset:\n")
print(data)
print("\n-----------------------------------\n")

# Function to calculate entropy
def entropy(target_col):
    elements, counts = np.unique(target_col, return_counts=True)
    entropy_value = 0
    for i in range(len(elements)):
        probability = counts[i] / np.sum(counts)
        entropy_value += -probability * math.log2(probability)
    return entropy_value

# Function to calculate Information Gain
def information_gain(data, attribute, target_name="PlayTennis"):
    
    total_entropy = entropy(data[target_name])
    
    values, counts = np.unique(data[attribute], return_counts=True)
    
    weighted_entropy = 0
    for i in range(len(values)):
        subset = data[data[attribute] == values[i]]
        weighted_entropy += (counts[i] / np.sum(counts)) * entropy(subset[target_name])
    
    return total_entropy - weighted_entropy

# ID3 Algorithm
def id3(data, originaldata, features, target_name="PlayTennis", parent_node_class=None):
    
    # If all target values are same, return that value
    if len(np.unique(data[target_name])) <= 1:
        return np.unique(data[target_name])[0]
    
    # If dataset is empty
    elif len(data) == 0:
        return np.unique(originaldata[target_name])[np.argmax(
            np.unique(originaldata[target_name], return_counts=True)[1])]
    
    # If no features left
    elif len(features) == 0:
        return parent_node_class
    
    else:
        parent_node_class = np.unique(data[target_name])[np.argmax(
            np.unique(data[target_name], return_counts=True)[1])]
        
        # Calculate Information Gain for each feature
        item_values = [information_gain(data, feature, target_name) for feature in features]
        
        # Best feature
        best_feature_index = np.argmax(item_values)
        best_feature = features[best_feature_index]
        
        tree = {best_feature: {}}
        
        features = [i for i in features if i != best_feature]
        
        # Grow tree
        for value in np.unique(data[best_feature]):
            sub_data = data[data[best_feature] == value]
            subtree = id3(sub_data, data, features, target_name, parent_node_class)
            tree[best_feature][value] = subtree
        
        return tree

# Features list
features = list(data.columns[:-1])

# Build Decision Tree
tree = id3(data, data, features)

print("Generated Decision Tree:\n")
print(tree)
